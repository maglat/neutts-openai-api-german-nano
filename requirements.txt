fastapi>=0.110
uvicorn[standard]>=0.27
pydantic>=2.6

numpy>=1.26
soundfile>=0.12
python-multipart>=0.0.9
orjson>=3.9

# Hugging Face Hub / caching
huggingface-hub>=0.23

# Core TTS stack (laut Model Card)
neutts

# Optional: ONNX decoder support (laut Model Card + ONNX Decoder Card)
onnxruntime>=1.16

# Optional: GGUF runtime (CPU-only by default; GPU via custom build)
llama-cpp-python
